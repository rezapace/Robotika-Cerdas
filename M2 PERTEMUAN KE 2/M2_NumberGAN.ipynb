{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0,\n",
    "  \"metadata\": {\n",
    "    \"accelerator\": \"GPU\",\n",
    "    \"colab\": {\n",
    "      \"name\": \"NumberGAN_Solution.ipynb\",\n",
    "      \"provenance\": [],\n",
    "      \"collapsed_sections\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\"\n",
    "    }\n",
    "  },\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"NJp-D51g0IDd\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## **1) Importing Python Packages for GAN**\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"1k5mFBuzzl2a\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"from keras.datasets import mnist\\n\",\n",
    "        \"\\n\",\n",
    "        \"from keras.models import Sequential\\n\",\n",
    "        \"from keras.layers import BatchNormalization\\n\",\n",
    "        \"from keras.layers import Dense, Reshape, Flatten\\n\",\n",
    "        \"from keras.layers.advanced_activations import LeakyReLU\\n\",\n",
    "        \"from tensorflow.keras.optimizers import Adam\\n\",\n",
    "        \"\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"!mkdir generated_images\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Yr-eZOzg0X79\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## **2) Variables for Neural Networks & Data**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"RThZMDruz9cB\",\n",
    "        \"outputId\": \"ac040e71-9a75-4061-ef7d-5361f31bc976\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"img_width = 28\\n\",\n",
    "        \"img_height = 28\\n\",\n",
    "        \"channels = 1\\n\",\n",
    "        \"img_shape = (img_width, img_height, channels)\\n\",\n",
    "        \"latent_dim = 100\\n\",\n",
    "        \"adam = Adam(lr=0.0001)\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stderr\",\n",
    "          \"text\": [\n",
    "            \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\\n\",\n",
    "            \"  super(Adam, self).__init__(name, **kwargs)\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"U3bcJZZg0cqy\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## **3) Building Generator**\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"NdiqZpri0iQh\",\n",
    "        \"outputId\": \"166dfc32-17f5-4613-d90a-d523b538d76f\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        }\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"def build_generator():\\n\",\n",
    "        \"  model = Sequential()\\n\",\n",
    "        \"\\n\",\n",
    "        \"  model.add(Dense(256, input_dim=latent_dim))\\n\",\n",
    "        \"  model.add(LeakyReLU(alpha=0.2))\\n\",\n",
    "        \"  model.add(BatchNormalization(momentum=0.8))\\n\",\n",
    "        \"\\n\",\n",
    "        \"  model.add(Dense(256))\\n\",\n",
    "        \"  model.add(LeakyReLU(alpha=0.2))\\n\",\n",
    "        \"  model.add(BatchNormalization(momentum=0.8))\\n\",\n",
    "        \"\\n\",\n",
    "        \"  model.add(Dense(256))\\n\",\n",
    "        \"  model.add(LeakyReLU(alpha=0.2))\\n\",\n",
    "        \"  model.add(BatchNormalization(momentum=0.8))\\n\",\n",
    "        \"\\n\",\n",
    "        \"  model.add(Dense(np.prod(img_shape), activation='tanh'))\\n\",\n",
    "        \"  model.add(Reshape(img_shape))\\n\",\n",
    "        \"  \\n\",\n",
    "        \"  model.summary()\\n\",\n",
    "        \"  return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"generator = build_generator()\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"Model: \\\"sequential\\\"\\n\",\n",
    "            \"_________________________________________________________________\\n\",\n",
    "            \" Layer (type)                Output Shape              Param #   \\n\",\n",
    "            \"=================================================================\\n\",\n",
    "            \" dense (Dense)               (None, 256)               25856     \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" leaky_re_lu (LeakyReLU)     (None, 256)               0         \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" batch_normalization (BatchN  (None, 256)              1024      \\n\",\n",
    "            \" ormalization)                                                   \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" dense_1 (Dense)             (None, 256)               65792     \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" batch_normalization_1 (Batc  (None, 256)              1024      \\n\",\n",
    "            \" hNormalization)                                                 \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" dense_2 (Dense)             (None, 256)               65792     \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" batch_normalization_2 (Batc  (None, 256)              1024      \\n\",\n",
    "            \" hNormalization)                                                 \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" dense_3 (Dense)             (None, 784)               201488    \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" reshape (Reshape)           (None, 28, 28, 1)         0         \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \"=================================================================\\n\",\n",
    "            \"Total params: 362,000\\n\",\n",
    "            \"Trainable params: 360,464\\n\",\n",
    "            \"Non-trainable params: 1,536\\n\",\n",
    "            \"_________________________________________________________________\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Bt6QsJCW0mcI\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## **4) Building Discriminator**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"V2JzEAPv0lKt\",\n",
    "        \"outputId\": \"c5dc2705-5b5f-4c83-89f5-731ae33203ec\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"def build_discriminator():\\n\",\n",
    "        \"  model = Sequential()\\n\",\n",
    "        \"\\n\",\n",
    "        \"  model.add(Flatten(input_shape=img_shape))\\n\",\n",
    "        \"  model.add(Dense(512))\\n\",\n",
    "        \"  model.add(LeakyReLU(alpha=0.2))\\n\",\n",
    "        \"  model.add(Dense(256))\\n\",\n",
    "        \"  model.add(Dense(1, activation='sigmoid'))\\n\",\n",
    "        \"\\n\",\n",
    "        \"  model.summary()\\n\",\n",
    "        \"  return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"discriminator = build_discriminator()\\n\",\n",
    "        \"discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"Model: \\\"sequential_1\\\"\\n\",\n",
    "            \"_________________________________________________________________\\n\",\n",
    "            \" Layer (type)                Output Shape              Param #   \\n\",\n",
    "            \"=================================================================\\n\",\n",
    "            \" flatten (Flatten)           (None, 784)               0         \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" dense_4 (Dense)             (None, 512)               401920    \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" dense_5 (Dense)             (None, 256)               131328    \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" dense_6 (Dense)             (None, 1)                 257       \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \"=================================================================\\n\",\n",
    "            \"Total params: 533,505\\n\",\n",
    "            \"Trainable params: 533,505\\n\",\n",
    "            \"Non-trainable params: 0\\n\",\n",
    "            \"_________________________________________________________________\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"TbcKcKmA0q2S\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## **5) Connecting Neural Networks to build GAN**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"q0Ue3TEd0xLy\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"491bfb8d-db71-4ef5-c636-8a3c918b64d5\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"GAN = Sequential()\\n\",\n",
    "        \"discriminator.trainable = False\\n\",\n",
    "        \"GAN.add(generator)\\n\",\n",
    "        \"GAN.add(discriminator)\\n\",\n",
    "        \"\\n\",\n",
    "        \"GAN.compile(loss='binary_crossentropy', optimizer=adam)\\n\",\n",
    "        \"GAN.summary()\\n\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"Model: \\\"sequential_2\\\"\\n\",\n",
    "            \"_________________________________________________________________\\n\",\n",
    "            \" Layer (type)                Output Shape              Param #   \\n\",\n",
    "            \"=================================================================\\n\",\n",
    "            \" sequential (Sequential)     (None, 28, 28, 1)         362000    \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \" sequential_1 (Sequential)   (None, 1)                 533505    \\n\",\n",
    "            \"                                                                 \\n\",\n",
    "            \"=================================================================\\n\",\n",
    "            \"Total params: 895,505\\n\",\n",
    "            \"Trainable params: 360,464\\n\",\n",
    "            \"Non-trainable params: 535,041\\n\",\n",
    "            \"_________________________________________________________________\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"2WaNhBDwRwTG\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## **6) Outputting Images**\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"HQEJ0WbjRppy\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"#@title\\n\",\n",
    "        \"## **7) Outputting Images**\\n\",\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import glob\\n\",\n",
    "        \"import imageio\\n\",\n",
    "        \"import PIL\\n\",\n",
    "        \"\\n\",\n",
    "        \"save_name = 0.00000000\\n\",\n",
    "        \"\\n\",\n",
    "        \"def save_imgs(epoch):\\n\",\n",
    "        \"    r, c = 5, 5\\n\",\n",
    "        \"    noise = np.random.normal(0, 1, (r * c, latent_dim))\\n\",\n",
    "        \"    gen_imgs = generator.predict(noise)\\n\",\n",
    "        \"    global save_name\\n\",\n",
    "        \"    save_name += 0.00000001\\n\",\n",
    "        \"    print(\\\"%.8f\\\" % save_name)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # Rescale images 0 - 1\\n\",\n",
    "        \"    gen_imgs = 0.5 * gen_imgs + 0.5\\n\",\n",
    "        \"\\n\",\n",
    "        \"    fig, axs = plt.subplots(r, c)\\n\",\n",
    "        \"    cnt = 0\\n\",\n",
    "        \"    for i in range(r):\\n\",\n",
    "        \"        for j in range(c):\\n\",\n",
    "        \"            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\\n\",\n",
    "        \"            # axs[i,j].imshow(gen_imgs[cnt])\\n\",\n",
    "        \"            axs[i,j].axis('off')\\n\",\n",
    "        \"            cnt += 1\\n\",\n",
    "        \"    fig.savefig(\\\"generated_images/%.8f.png\\\" % save_name)\\n\",\n",
    "        \"    print('saved')\\n\",\n",
    "        \"    plt.close()\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"tE57Lk5V0xs2\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## **7) Training GAN**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"egSJJvik00Iq\",\n",
    "        \"outputId\": \"31c8c38f-dafd-41b3-e976-4f68473a9922\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 1000\n",
    "        }\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"def train(epochs, batch_size=64, save_interval=200):\\n\",\n",
    "        \"  (X_train, _), (_, _) = mnist.load_data()\\n\",\n",
    "        \"\\n\",\n",
    "        \"  # print(X_train.shape)\\n\",\n",
    "        \"  #Rescale data between -1 and 1\\n\",\n",
    "        \"  X_train = X_train / 127.5 -1.\\n\",\n",
    "        \"  # X_train = np.expand_dims(X_train, axis=3)\\n\",\n",
    "        \"  # print(X_train.shape)\\n\",\n",
    "        \"\\n\",\n",
    "        \"  #Create our Y for our Neural Networks\\n\",\n",
    "        \"  valid = np.ones((batch_size, 1))\\n\",\n",
    "        \"  fakes = np.zeros((batch_size, 1))\\n\",\n",
    "        \"\\n\",\n",
    "        \"  for epoch in range(epochs):\\n\",\n",
    "        \"    #Get Random Batch\\n\",\n",
    "        \"    idx = np.random.randint(0, X_train.shape[0], batch_size)\\n\",\n",
    "        \"    imgs = X_train[idx]\\n\",\n",
    "        \"\\n\",\n",
    "        \"    #Generate Fake Images\\n\",\n",
    "        \"    noise = np.random.normal(0, 1, (batch_size, latent_dim))\\n\",\n",
    "        \"    gen_imgs = generator.predict(noise)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    #Train discriminator\\n\",\n",
    "        \"    d_loss_real = discriminator.train_on_batch(imgs, valid)\\n\",\n",
    "        \"    d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\\n\",\n",
    "        \"    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    noise = np.random.normal(0, 1, (batch_size, latent_dim))\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    #inverse y label\\n\",\n",
    "        \"    g_loss = GAN.train_on_batch(noise, valid)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    print(\\\"******* %d [D loss: %f, acc: %.2f%%] [G loss: %f]\\\" % (epoch, d_loss[0], 100* d_loss[1], g_loss))\\n\",\n",
    "        \"\\n\",\n",
    "        \"    if(epoch % save_interval) == 0:\\n\",\n",
    "        \"      save_imgs(epoch)\\n\",\n",
    "        \"\\n\",\n",
    "        \"  # print(valid)\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"train(30000, batch_size=64, save_interval=200)\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"output_type\": \"stream\",\n",
    "          \"name\": \"stdout\",\n",
    "          \"text\": [\n",
    "            \"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\\n\",\n",
    "            \"11493376/11490434 [==============================] - 0s 0us/step\\n\",\n",
    "            \"11501568/11490434 [==============================] - 0s 0us/step\\n\",\n",
    "            \"******* 0 [D loss: 0.887595, acc: 45.31%] [G loss: 0.767116]\\n\",\n",
    "            \"0.00000001\\n\",\n",
    "            \"saved\\n\",\n",
    "            \"******* 1 [D loss: 0.405668, acc: 79.69%] [G loss: 0.748326]\\n\",\n",
    "            \"******* 2 [D loss: 0.345956, acc: 80.47%] [G loss: 0.739114]\\n\",\n",
    "            \"******* 3 [D loss: 0.333020, acc: 82.81%] [G loss: 0.706251]\\n\",\n",
    "            \"******* 4 [D loss: 0.342352, acc: 78.12%] [G loss: 0.756652]\\n\",\n",
    "            \"******* 5 [D loss: 0.337693, acc: 79.69%] [G loss: 0.819206]\\n\",\n",
    "            \"******* 6 [D loss: 0.320905, acc: 78.91%] [G loss: 0.855542]\\n\",\n",
    "            \"******* 7 [D loss: 0.306857, acc: 82.81%] [G loss: 0.936298]\\n\",\n",
    "            \"******* 8 [D loss: 0.293247, acc: 89.84%] [G loss: 1.036027]\\n\",\n",
    "            \"******* 9 [D loss: 0.255740, acc: 94.53%] [G loss: 1.078977]\\n\",\n",
    "            \"******* 10 [D loss: 0.257833, acc: 90.62%] [G loss: 1.192591]\\n\",\n",
    "            \"******* 11 [D loss: 0.220323, acc: 96.88%] [G loss: 1.303853]\\n\",\n",
    "            \"******* 12 [D loss: 0.190162, acc: 100.00%] [G loss: 1.428722]\\n\",\n",
    "            \"******* 13 [D loss: 0.154554, acc: 99.22%] [G loss: 1.608374]\\n\",\n",
    "            \"******* 14 [D loss: 0.127561, acc: 100.00%] [G loss: 1.714983]\\n\",\n",
    "            \"******* 15 [D loss: 0.111209, acc: 100.00%] [G loss: 1.838400]\\n\",\n",
    "            \"******* 16 [D loss: 0.099721, acc: 100.00%] [G loss: 1.952587]\\n\",\n",
    "            \"******* 17 [D loss: 0.087172, acc: 100.00%] [G loss: 2.059102]\\n\",\n",
    "            \"******* 18 [D loss: 0.071507, acc: 100.00%] [G loss: 2.179142]\\n\",\n",
    "            \"******* 19 [D loss: 0.070814, acc: 100.00%] [G loss: 2.304069]\\n\",\n",
    "            \"******* 20 [D loss: 0.057023, acc: 100.00%] [G loss: 2.445385]\\n\",\n",
    "            \"******* 21 [D loss: 0.053082, acc: 100.00%] [G loss: 2.542961]\\n\",\n",
    "            \"******* 22 [D loss: 0.051527, acc: 100.00%] [G loss: 2.610686]\\n\",\n",
    "            \"******* 23 [D loss: 0.044485, acc: 100.00%] [G loss: 2.631511]\\n\",\n",
    "            \"******* 24 [D loss: 0.038197, acc: 100.00%] [G loss: 2.727536]\\n\",\n",
    "            \"******* 25 [D loss: 0.038307, acc: 100.00%] [G loss: 2.784837]\\n\",\n",
    "            \"******* 26 [D loss: 0.039958, acc: 100.00%] [G loss: 2.876319]\\n\",\n",
    "            \"******* 27 [D loss: 0.035662, acc: 100.00%] [G loss: 2.928057]\\n\",\n",
    "            \"******* 28 [D loss: 0.031384, acc: 100.00%] [G loss: 2.962376]\\n\",\n",
    "            \"******* 29 [D loss: 0.029348, acc: 100.00%] [G loss: 3.014545]\\n\",\n",
    "            \"******* 30 [D loss: 0.030065, acc: 100.00%] [G loss: 3.075484]\\n\",\n",
    "            \"******* 31 [D loss: 0.026830, acc: 100.00%] [G loss: 3.062098]\\n\",\n",
    "            \"******* 32 [D loss: 0.027748, acc: 100.00%] [G loss: 3.062397]\\n\",\n",
    "            \"******* 33 [D loss: 0.025648, acc: 100.00%] [G loss: 3.101132]\\n\",\n",
    "            \"******* 34 [D loss: 0.028176, acc: 100.00%] [G loss: 3.107950]\\n\",\n",
    "            \"******* 35 [D loss: 0.025816, acc: 100.00%] [G loss: 3.163767]\\n\",\n",
    "            \"******* 36 [D loss: 0.026522, acc: 100.00%] [G loss: 3.240295]\\n\",\n",
    "            \"******* 37 [D loss: 0.026216, acc: 100.00%] [G loss: 3.189269]\\n\",\n",
    "            \"******* 38 [D loss: 0.024015, acc: 100.00%] [G loss: 3.169399]\\n\",\n",
    "            \"******* 39 [D loss: 0.022231, acc: 100.00%] [G loss: 3.115056]\\n\",\n",
    "            \"******* 40 [D loss: 0.027552, acc: 100.00%] [G loss: 3.181084]\\n\",\n",
    "            \"******* 41 [D loss: 0.022812, acc: 100.00%] [G loss: 3.193994]\\n\",\n",
    "            \"******* 42 [D loss: 0.024095, acc: 100.00%] [G loss: 3.172971]\\n\",\n",
    "            \"******* 43 [D loss: 0.022707, acc: 100.00%] [G loss: 3.139848]\\n\",\n",
    "            \"******* 44 [D loss: 0.021686, acc: 100.00%] [G loss: 3.289233]\\n\",\n",
    "            \"******* 45 [D loss: 0.020121, acc: 100.00%] [G loss: 3.285497]\\n\",\n",
    "            \"******* 46 [D loss: 0.021227, acc: 100.00%] [G loss: 3.194090]\\n\",\n",
    "            \"******* 47 [D loss: 0.021577, acc: 100.00%] [G loss: 3.272365]\\n\",\n",
    "            \"******* 48 [D loss: 0.020971, acc: 100.00%] [G loss: 3.294955]\\n\",\n",
    "            \"******* 49 [D loss: 0.023383, acc: 100.00%] [G loss: 3.324584]\\n\",\n",
    "            \"******* 50 [D loss: 0.024454, acc: 100.00%] [G loss: 3.295917]\\n\",\n",
    "            \"******* 51 [D loss: 0.020467, acc: 100.00%] [G loss: 3.298032]\\n\",\n",
    "            \"******* 52 [D loss: 0.020744, acc: 100.00%] [G loss: 3.281011]\\n\",\n",
    "            \"******* 53 [D loss: 0.022824, acc: 100.00%] [G loss: 3.300265]\\n\",\n",
    "            \"******* 54 [D loss: 0.024983, acc: 100.00%] [G loss: 3.380123]\\n\",\n",
    "            \"******* 55 [D loss: 0.021341, acc: 100.00%] [G loss: 3.279719]\\n\",\n",
    "            \"******* 56 [D loss: 0.022923, acc: 100.00%] [G loss: 3.344484]\\n\",\n",
    "            \"******* 57 [D loss: 0.021996, acc: 100.00%] [G loss: 3.402670]\\n\",\n",
    "            \"******* 58 [D loss: 0.020633, acc: 100.00%] [G loss: 3.335642]\\n\",\n",
    "            \"******* 59 [D loss: 0.020644, acc: 100.00%] [G loss: 3.330906]\\n\",\n",
    "            \"******* 60 [D loss: 0.020034, acc: 100.00%] [G loss: 3.470451]\\n\",\n",
    "            \"******* 61 [D loss: 0.020317, acc: 100.00%] [G loss: 3.445269]\\n\",\n",
    "            \"******* 62 [D loss: 0.017723, acc: 100.00%] [G loss: 3.494688]\\n\",\n",
    "            \"******* 63 [D loss: 0.017043, acc: 100.00%] [G loss: 3.413889]\\n\",\n",
    "            \"******* 64 [D loss: 0.018582, acc: 100.00%] [G loss: 3.403938]\\n\",\n",
    "            \"******* 65 [D loss: 0.017904, acc: 100.00%] [G loss: 3.410262]\\n\",\n",
    "            \"******* 66 [D loss: 0.020047, acc: 100.00%] [G loss: 3.455626]\\n\",\n",
    "            \"******* 67 [D loss: 0.021032, acc: 100.00%] [G loss: 3.537026]\\n\",\n",
    "            \"******* 68 [D loss: 0.016465, acc: 100.00%] [G loss: 3.526901]\\n\",\n",
    "            \"******* 69 [D loss: 0.019209, acc: 100.00%] [G loss: 3.425596]\\n\",\n",
    "            \"******* 70 [D loss: 0.018885, acc: 100.00%] [G loss: 3.442147]\\n\",\n",
    "            \"******* 71 [D loss: 0.016517, acc: 100.00%] [G loss: 3.517414]\\n\",\n",
    "            \"******* 72 [D loss: 0.018187, acc: 100.00%] [G loss: 3.487462]\\n\",\n",
    "            \"******* 73 [D loss: 0.018853, acc: 100.00%] [G loss: 3.623919]\\n\",\n",
    "            \"******* 74 [D loss: 0.019464, acc: 100.00%] [G loss: 3.580263]\\n\",\n",
    "            \"******* 75 [D loss: 0.017221, acc: 100.00%] [G loss: 3.565736]\\n\",\n",
    "            \"******* 76 [D loss: 0.017446, acc: 100.00%] [G loss: 3.607656]\\n\",\n",
    "            \"******* 77 [D loss: 0.016478, acc: 100.00%] [G loss: 3.635428]\\n\",\n",
    "            \"******* 78 [D loss: 0.014950, acc: 100.00%] [G loss: 3.642250]\\n\",\n",
    "            \"******* 79 [D loss: 0.016156, acc: 100.00%] [G loss: 3.589338]\\n\",\n",
    "            \"******* 80 [D loss: 0.018331, acc: 100.00%] [G loss: 3.656942]\\n\",\n",
    "            \"******* 81 [D loss: 0.014726, acc: 100.00%] [G loss: 3.678287]\\n\",\n",
    "            \"******* 82 [D loss: 0.015382, acc: 100.00%] [G loss: 3.660866]\\n\",\n",
    "            \"******* 83 [D loss: 0.015488, acc: 100.00%] [G loss: 3.605052]\\n\",\n",
    "            \"******* 84 [D loss: 0.013401, acc: 100.00%] [G loss: 3.606966]\\n\",\n",
    "            \"******* 85 [D loss: 0.016101, acc: 100.00%] [G loss: 3.627815]\\n\",\n",
    "            \"******* 86 [D loss: 0.014191, acc: 100.00%] [G loss: 3.718097]\\n\",\n",
    "            \"******* 87 [D loss: 0.014471, acc: 100.00%] [G loss: 3.624797]\\n\",\n",
    "            \"******* 88 [D loss: 0.014437, acc: 100.00%] [G loss: 3.716690]\\n\",\n",
    "            \"******* 89 [D loss: 0.016792, acc: 100.00%] [G loss: 3.671373]\\n\",\n",
    "            \"******* 90 [D loss: 0.013195, acc: 100.00%] [G loss: 3.625812]\\n\",\n",
    "            \"******* 91 [D loss: 0.014900, acc: 100.00%] [G loss: 3.671586]\\n\",\n",
    "            \"******* 92 [D loss: 0.014911, acc: 100.00%] [G loss: 3.645650]\\n\",\n",
    "            \"******* 93 [D loss: 0.016027, acc: 100.00%] [G loss: 3.782292]\\n\",\n",
    "            \"******* 94 [D loss: 0.012193, acc: 100.00%] [G loss: 3.710413]\\n\",\n",
    "            \"******* 95 [D loss: 0.014391, acc: 100.00%] [G loss: 3.665170]\\n\",\n",
    "            \"******* 96 [D loss: 0.014872, acc: 100.00%] [G loss: 3.713327]\\n\",\n",
    "            \"******* 97 [D loss: 0.014552, acc: 100.00%] [G loss: 3.784928]\\n\",\n",
    "            \"******* 98 [D loss: 0.014155, acc: 100.00%] [G loss: 3.741305]\\n\",\n",
    "            \"******* 99 [D loss: 0.015092, acc: 100.00%] [G loss: 3.782977]\\n\",\n",
    "            \"******* 100 [D loss: 0.011584, acc: 100.00%] [G loss: 3.801511]\\n\",\n",
    "            \"******* 101 [D loss: 0.012497, acc: 100.00%] [G loss: 3.818971]\\n\",\n",
    "            \"******* 102 [D loss: 0.014930, acc: 100.00%] [G loss: 3.809093]\\n\",\n",
    "            \"******* 103 [D loss: 0.014322, acc: 100.00%] [G loss: 3.833256]\\n\",\n",
    "            \"******* 104 [D loss: 0.013602, acc: 100.00%] [G loss: 3.793944]\\n\",\n",
    "            \"******* 105 [D loss: 0.014410, acc: 100.00%] [G loss: 3.803089]\\n\",\n",
    "            \"******* 106 [D loss: 0.013783, acc: 100.00%] [G loss: 3.939082]\\n\",\n",
    "            \"******* 107 [D loss: 0.015252, acc: 100.00%] [G loss: 3.883614]\\n\",\n",
    "            \"******* 108 [D loss: 0.015102, acc: 100.00%] [G loss: 3.796621]\\n\",\n",
    "            \"******* 109 [D loss: 0.013292, acc: 100.00%] [G loss: 3.895370]\\n\",\n",
    "            \"******* 110 [D loss: 0.012461, acc: 100.00%] [G loss: 3.905505]\\n\",\n",
    "            \"******* 111 [D loss: 0.014754, acc: 100.00%] [G loss: 3.892162]\\n\",\n",
    "            \"******* 112 [D loss: 0.013246, acc: 100.00%] [G loss: 3.945469]\\n\",\n",
    "            \"******* 113 [D loss: 0.012612, acc: 100.00%] [G loss: 3.985584]\\n\",\n",
    "            \"******* 114 [D loss: 0.010890, acc: 100.00%] [G loss: 3.948858]\\n\",\n",
    "            \"******* 115 [D loss: 0.011326, acc: 100.00%] [G loss: 3.890499]\\n\",\n",
    "            \"******* 116 [D loss: 0.012697, acc: 100.00%] [G loss: 4.002373]\\n\",\n",
    "            \"******* 117 [D loss: 0.012974, acc: 100.00%] [G loss: 3.930768]\\n\",\n",
    "            \"******* 118 [D loss: 0.011039, acc: 100.00%] [G loss: 3.949944]\\n\",\n",
    "            \"******* 119 [D loss: 0.011074, acc: 100.00%] [G loss: 3.998259]\\n\",\n",
    "            \"******* 120 [D loss: 0.011042, acc: 100.00%] [G loss: 3.986333]\\n\",\n",
    "            \"******* 121 [D loss: 0.011805, acc: 100.00%] [G loss: 3.995777]\\n\",\n",
    "            \"******* 122 [D loss: 0.013568, acc: 100.00%] [G loss: 3.985265]\\n\",\n",
    "            \"******* 123 [D loss: 0.012082, acc: 100.00%] [G loss: 3.960634]\\n\",\n",
    "            \"******* 124 [D loss: 0.011091, acc: 100.00%] [G loss: 3.933666]\\n\",\n",
    "            \"******* 125 [D loss: 0.010086, acc: 100.00%] [G loss: 3.980640]\\n\",\n",
    "            \"******* 126 [D loss: 0.013468, acc: 100.00%] [G loss: 3.985919]\\n\",\n",
    "            \"******* 127 [D loss: 0.010646, acc: 100.00%] [G loss: 4.002507]\\n\",\n",
    "            \"******* 128 [D loss: 0.011896, acc: 100.00%] [G loss: 4.094346]\\n\",\n",
    "            \"******* 129 [D loss: 0.011810, acc: 100.00%] [G loss: 4.002273]\\n\",\n",
    "            \"******* 130 [D loss: 0.012047, acc: 100.00%] [G loss: 3.963717]\\n\",\n",
    "            \"******* 131 [D loss: 0.010916, acc: 100.00%] [G loss: 4.052400]\\n\",\n",
    "            \"******* 132 [D loss: 0.011625, acc: 100.00%] [G loss: 4.096560]\\n\",\n",
    "            \"******* 133 [D loss: 0.012737, acc: 100.00%] [G loss: 3.988784]\\n\",\n",
    "            \"******* 134 [D loss: 0.013214, acc: 100.00%] [G loss: 4.032121]\\n\",\n",
    "            \"******* 135 [D loss: 0.011826, acc: 100.00%] [G loss: 4.120291]\\n\",\n",
    "            \"******* 136 [D loss: 0.012068, acc: 100.00%] [G loss: 4.089785]\\n\",\n",
    "            \"******* 137 [D loss: 0.012541, acc: 100.00%] [G loss: 4.083216]\\n\",\n",
    "            \"******* 138 [D loss: 0.011955, acc: 100.00%] [G loss: 4.098425]\\n\",\n",
    "            \"******* 139 [D loss: 0.012130, acc: 100.00%] [G loss: 4.087247]\\n\",\n",
    "            \"******* 140 [D loss: 0.010949, acc: 100.00%] [G loss: 4.084918]\\n\",\n",
    "            \"******* 141 [D loss: 0.013981, acc: 100.00%] [G loss: 4.190564]\\n\",\n",
    "            \"******* 142 [D loss: 0.010937, acc: 100.00%] [G loss: 4.140103]\\n\",\n",
    "            \"******* 143 [D loss: 0.010748, acc: 100.00%] [G loss: 4.162172]\\n\",\n",
    "            \"******* 144 [D loss: 0.009542, acc: 100.00%] [G loss: 4.200652]\\n\",\n",
    "            \"******* 145 [D loss: 0.010746, acc: 100.00%] [G loss: 4.171209]\\n\",\n",
    "            \"******* 146 [D loss: 0.010589, acc: 100.00%] [G loss: 4.136430]\\n\",\n",
    "            \"******* 147 [D loss: 0.010427, acc: 100.00%] [G loss: 4.103925]\\n\",\n",
    "            \"******* 148 [D loss: 0.011179, acc: 100.00%] [G loss: 4.218429]\\n\",\n",
    "            \"******* 149 [D loss: 0.009774, acc: 100.00%] [G loss: 4.117167]\\n\",\n",
    "            \"******* 150 [D loss: 0.007518, acc: 100.00%] [G loss: 4.169094]\\n\",\n",
    "            \"******* 151 [D loss: 0.011142, acc: 100.00%] [G loss: 4.203152]\\n\",\n",
    "            \"******* 152 [D loss: 0.012431, acc: 100.00%] [G loss: 4.154524]\\n\",\n",
    "            \"******* 153 [D loss: 0.011954, acc: 100.00%] [G loss: 4.204410]\\n\",\n",
    "            \"******* 154 [D loss: 0.012326, acc: 100.00%] [G loss: 4.136154]\\n\",\n",
    "            \"******* 155 [D loss: 0.011123, acc: 100.00%] [G loss: 4.180346]\\n\",\n",
    "            \"******* 156 [D loss: 0.013107, acc: 100.00%] [G loss: 4.183456]\\n\",\n",
    "            \"******* 157 [D loss: 0.012936, acc: 100.00%] [G loss: 4.209165]\\n\",\n",
    "            \"******* 158 [D loss: 0.009622, acc: 100.00%] [G loss: 4.163790]\\n\",\n",
    "            \"******* 159 [D loss: 0.010726, acc: 100.00%] [G loss: 4.167893]\\n\",\n",
    "            \"******* 160 [D loss: 0.010121, acc: 100.00%] [G loss: 4.178885]\\n\",\n",
    "            \"******* 161 [D loss: 0.010749, acc: 100.00%] [G loss: 4.238237]\\n\",\n",
    "            \"******* 162 [D loss: 0.012310, acc: 100.00%] [G loss: 4.186337]\\n\",\n",
    "            \"******* 163 [D loss: 0.010503, acc: 100.00%] [G loss: 4.124057]\\n\",\n",
    "            \"******* 164 [D loss: 0.010563, acc: 100.00%] [G loss: 4.205729]\\n\",\n",
    "            \"******* 165 [D loss: 0.011089, acc: 100.00%] [G loss: 4.197129]\\n\",\n",
    "            \"******* 166 [D loss: 0.010497, acc: 100.00%] [G loss: 4.156010]\\n\",\n",
    "            \"******* 167 [D loss: 0.011136, acc: 100.00%] [G loss: 4.236703]\\n\",\n",
    "            \"******* 168 [D loss: 0.010258, acc: 100.00%] [G loss: 4.246906]\\n\",\n",
    "            \"******* 169 [D loss: 0.009465, acc: 100.00%] [G loss: 4.223343]\\n\",\n",
    "            \"******* 170 [D loss: 0.010778, acc: 100.00%] [G loss: 4.217636]\\n\",\n",
    "            \"******* 171 [D loss: 0.008611, acc: 100.00%] [G loss: 4.254766]\\n\",\n",
    "            \"******* 172 [D loss: 0.011502, acc: 100.00%] [G loss: 4.221816]\\n\",\n",
    "            \"******* 173 [D loss: 0.010251, acc: 100.00%] [G loss: 4.213115]\\n\",\n",
    "            \"******* 174 [D loss: 0.009654, acc: 100.00%] [G loss: 4.186604]\\n\",\n",
    "            \"******* 175 [D loss: 0.013229, acc: 100.00%] [G loss: 4.282515]\\n\",\n",
    "            \"******* 176 [D loss: 0.009973, acc: 100.00%] [G loss: 4.315389]\\n\",\n",
    "            \"******* 177 [D loss: 0.010999, acc: 100.00%] [G loss: 4.242590]\\n\",\n",
    "            \"******* 178 [D loss: 0.012218, acc: 100.00%] [G loss: 4.266191]\\n\",\n",
    "            \"******* 179 [D loss: 0.012456, acc: 100.00%] [G loss: 4.224841]\\n\",\n",
    "            \"******* 180 [D loss: 0.010897, acc: 100.00%] [G loss: 4.221921]\\n\",\n",
    "            \"******* 181 [D loss: 0.012384, acc: 100.00%] [G loss: 4.153231]\\n\",\n",
    "            \"******* 182 [D loss: 0.011222, acc: 100.00%] [G loss: 4.293744]\\n\",\n",
    "            \"******* 183 [D loss: 0.007915, acc: 100.00%] [G loss: 4.245959]\\n\",\n",
    "            \"******* 184 [D loss: 0.011411, acc: 100.00%] [G loss: 4.280692]\\n\",\n",
    "            \"******* 185 [D loss: 0.012344, acc: 100.00%] [G loss: 4.282751]\\n\",\n",
    "            \"******* 186 [D loss: 0.011200, acc: 100.00%] [G loss: 4.272342]\\n\",\n",
    "            \"******* 187 [D loss: 0.013320, acc: 100.00%] [G loss: 4.303705]\\n\",\n",
    "            \"******* 188 [D loss: 0.009549, acc: 100.00%] [G loss: 4.353040]\\n\",\n",
    "            \"******* 189 [D loss: 0.009165, acc: 100.00%] [G loss: 4.358019]\\n\",\n",
    "            \"******* 190 [D loss: 0.012916, acc: 100.00%] [G loss: 4.264126]\\n\",\n",
    "            \"******* 191 [D loss: 0.010233, acc: 100.00%] [G loss: 4.249420]\\n\",\n",
    "            \"******* 192 [D loss: 0.011190, acc: 100.00%] [G loss: 4.318624]\\n\",\n",
    "            \"******* 193 [D loss: 0.008964, acc: 100.00%] [G loss: 4.312602]\\n\",\n",
    "            \"******* 194 [D loss: 0.010020, acc: 100.00%] [G loss: 4.398134]\\n\",\n",
    "            \"******* 195 [D loss: 0.010752, acc: 100.00%] [G loss: 4.277165]\\n\",\n",
    "            \"******* 196 [D loss: 0.011259, acc: 100.00%] [G loss: 4.253765]\\n\",\n",
    "            \"******* 197 [D loss: 0.010714, acc: 100.00%] [G loss: 4.291836]\\n\",\n",
    "            \"******* 198 [D loss: 0.009577, acc: 100.00%] [G loss: 4.337568]\\n\",\n",
    "            \"******* 199 [D loss: 0.010972, acc: 100.00%] [G loss: 4.321341]\\n\",\n",
    "            \"******* 200 [D loss: 0.011418, acc: 100.00%] [G loss: 4.362730]\\n\",\n",
    "            \"0.00000002\\n\",\n",
    "            \"saved\\n\",\n",
    "            \"******* 201 [D loss: 0.009933, acc: 100.00%] [G loss: 4.308037]\\n\",\n",
    "            \"******* 202 [D loss: 0.010024, acc: 100.00%] [G loss: 4.347883]\\n\",\n",
    "            \"******* 203 [D loss: 0.009041, acc: 100.00%] [G loss: 4.310122]\\n\",\n",
    "            \"******* 204 [D loss: 0.008538, acc: 100.00%] [G loss: 4.348898]\\n\",\n",
    "            \"******* 205 [D loss: 0.010756, acc: 100.00%] [G loss: 4.205606]\\n\",\n",
    "            \"******* 206 [D loss: 0.010113, acc: 100.00%] [G loss: 4.316840]\\n\",\n",
    "            \"******* 207 [D loss: 0.010625, acc: 100.00%] [G loss: 4.221187]\\n\",\n",
    "            \"******* 208 [D loss: 0.013296, acc: 100.00%] [G loss: 4.273458]\\n\",\n",
    "            \"******* 209 [D loss: 0.011574, acc: 100.00%] [G loss: 4.297751]\\n\",\n",
    "            \"******* 210 [D loss: 0.009893, acc: 100.00%] [G loss: 4.240689]\\n\",\n",
    "            \"******* 211 [D loss: 0.011143, acc: 100.00%] [G loss: 4.160333]\\n\",\n",
    "            \"******* 212 [D loss: 0.011955, acc: 100.00%] [G loss: 4.177412]\\n\",\n",
    "            \"******* 213 [D loss: 0.010818, acc: 100.00%] [G loss: 4.215970]\\n\",\n",
    "            \"******* 214 [D loss: 0.012480, acc: 100.00%] [G loss: 4.313668]\\n\",\n",
    "            \"******* 215 [D loss: 0.013620, acc: 100.00%] [G loss: 4.289402]\\n\",\n",
    "            \"******* 216 [D loss: 0.009655, acc: 100.00%] [G loss: 4.333922]\\n\",\n",
    "            \"******* 217 [D loss: 0.011663, acc: 100.00%] [G loss: 4.295591]\\n\",\n",
    "            \"******* 218 [D loss: 0.013272, acc: 100.00%] [G loss: 4.246381]\\n\",\n",
    "            \"******* 219 [D loss: 0.011881, acc: 100.00%] [G loss: 4.329163]\\n\",\n",
    "            \"******* 220 [D loss: 0.014982, acc: 100.00%] [G loss: 4.371473]\\n\",\n",
    "            \"******* 221 [D loss: 0.013422, acc: 100.00%] [G loss: 4.262572]\\n\",\n",
    "            \"******* 222 [D loss: 0.010737, acc: 100.00%] [G loss: 4.356739]\\n\",\n",
    "            \"******* 223 [D loss: 0.013434, acc: 100.00%] [G loss: 4.371290]\\n\",\n",
    "            \"******* 224 [D loss: 0.013243, acc: 100.00%] [G loss: 4.367368]\\n\",\n",
    "            \"******* 225 [D loss: 0.014152, acc: 100.00%] [G loss: 4.464168]\\n\",\n",
    "            \"******* 226 [D loss: 0.012541, acc: 100.00%] [G loss: 4.245787]\\n\",\n",
    "            \"******* 227 [D loss: 0.009646, acc: 100.00%] [G loss: 4.227634]\\n\",\n",
    "            \"******* 228 [D loss: 0.015385, acc: 100.00%] [G loss: 4.212928]\\n\",\n",
    "            \"******* 229 [D loss: 0.012583, acc: 100.00%] [G loss: 4.321209]\\n\",\n",
    "            \"******* 230 [D loss: 0.012570, acc: 100.00%] [G loss: 4.314577]\\n\",\n",
    "            \"******* 231 [D loss: 0.012439, acc: 100.00%] [G loss: 4.377110]\\n\",\n",
    "            \"******* 232 [D loss: 0.012377, acc: 100.00%] [G loss: 4.293907]\\n\",\n",
    "            \"******* 233 [D loss: 0.014652, acc: 100.00%] [G loss: 4.297708]\\n\",\n",
    "            \"******* 234 [D loss: 0.012556, acc: 100.00%] [G loss: 4.426029]\\n\",\n",
    "            \"******* 235 [D loss: 0.011466, acc: 100.00%] [G loss: 4.326212]\\n\"\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"output_type\": \"error\",\n",
    "          \"ename\": \"KeyboardInterrupt\",\n",
    "          \"evalue\": \"ignored\",\n",
    "          \"traceback\": [\n",
    "            \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
    "            \"\\u001b[0;31mKeyboardInterrupt\\u001b[0m                         Traceback (most recent call last)\",\n",
    "            \"\\u001b[0;32m<ipython-input-7-08179edae6ce>\\u001b[0m in \\u001b[0;36m<module>\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m     39\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     40\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m---> 41\\u001b[0;31m \\u001b[0mtrain\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;36m30000\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mbatch_size\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;36m64\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0msave_interval\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;36m200\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\",\n",
    "            \"\\u001b[0;32m<ipython-input-7-08179edae6ce>\\u001b[0m in \\u001b[0;36mtrain\\u001b[0;34m(epochs, batch_size, save_interval)\\u001b[0m\\n\\u001b[1;32m     19\\u001b[0m     \\u001b[0;31m#Generate Fake Images\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     20\\u001b[0m     \\u001b[0mnoise\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mnp\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mrandom\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mnormal\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;36m0\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;36m1\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m(\\u001b[0m\\u001b[0mbatch_size\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mlatent_dim\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m---> 21\\u001b[0;31m     \\u001b[0mgen_imgs\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mgenerator\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpredict\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mnoise\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     22\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     23\\u001b[0m     \\u001b[0;31m#Train discriminator\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\\u001b[0m in \\u001b[0;36merror_handler\\u001b[0;34m(*args, **kwargs)\\u001b[0m\\n\\u001b[1;32m     62\\u001b[0m     \\u001b[0mfiltered_tb\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     63\\u001b[0m     \\u001b[0;32mtry\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m---> 64\\u001b[0;31m       \\u001b[0;32mreturn\\u001b[0m \\u001b[0mfn\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     65\\u001b[0m     \\u001b[0;32mexcept\\u001b[0m \\u001b[0mException\\u001b[0m \\u001b[0;32mas\\u001b[0m \\u001b[0me\\u001b[0m\\u001b[0;34m:\\u001b[0m  \\u001b[0;31m# pylint: disable=broad-except\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     66\\u001b[0m       \\u001b[0mfiltered_tb\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0m_process_traceback_frames\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0me\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m__traceback__\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\\u001b[0m in \\u001b[0;36mpredict\\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\\u001b[0m\\n\\u001b[1;32m   1766\\u001b[0m           \\u001b[0muse_multiprocessing\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0muse_multiprocessing\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1767\\u001b[0m           \\u001b[0mmodel\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 1768\\u001b[0;31m           steps_per_execution=self._steps_per_execution)\\n\\u001b[0m\\u001b[1;32m   1769\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1770\\u001b[0m       \\u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\\u001b[0m in \\u001b[0;36mget_data_handler\\u001b[0;34m(*args, **kwargs)\\u001b[0m\\n\\u001b[1;32m   1401\\u001b[0m   \\u001b[0;32mif\\u001b[0m \\u001b[0mgetattr\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0;34m\\\"model\\\"\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m\\\"_cluster_coordinator\\\"\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1402\\u001b[0m     \\u001b[0;32mreturn\\u001b[0m \\u001b[0m_ClusterCoordinatorDataHandler\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 1403\\u001b[0;31m   \\u001b[0;32mreturn\\u001b[0m \\u001b[0mDataHandler\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   1404\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1405\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\\u001b[0m\\n\\u001b[1;32m   1163\\u001b[0m         \\u001b[0muse_multiprocessing\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0muse_multiprocessing\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1164\\u001b[0m         \\u001b[0mdistribution_strategy\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mtf\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mdistribute\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mget_strategy\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 1165\\u001b[0;31m         model=model)\\n\\u001b[0m\\u001b[1;32m   1166\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1167\\u001b[0m     \\u001b[0mstrategy\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mtf\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mdistribute\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mget_strategy\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\\u001b[0m\\n\\u001b[1;32m    289\\u001b[0m     \\u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    290\\u001b[0m     \\u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 291\\u001b[0;31m     \\u001b[0mindices_dataset\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mindices_dataset\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mmap\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mpermutation\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mprefetch\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;36m1\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    292\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    293\\u001b[0m     \\u001b[0;32mdef\\u001b[0m \\u001b[0mslice_batch_indices\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mindices\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\\u001b[0m in \\u001b[0;36mmap\\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\\u001b[0m\\n\\u001b[1;32m   2002\\u001b[0m         warnings.warn(\\\"The `deterministic` argument has no effect unless the \\\"\\n\\u001b[1;32m   2003\\u001b[0m                       \\\"`num_parallel_calls` argument is specified.\\\")\\n\\u001b[0;32m-> 2004\\u001b[0;31m       \\u001b[0;32mreturn\\u001b[0m \\u001b[0mMapDataset\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mmap_func\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mpreserve_cardinality\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;32mTrue\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mname\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mname\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   2005\\u001b[0m     \\u001b[0;32melse\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   2006\\u001b[0m       return ParallelMapDataset(\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\\u001b[0m\\n\\u001b[1;32m   5457\\u001b[0m         \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_transformation_name\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   5458\\u001b[0m         \\u001b[0mdataset\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0minput_dataset\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 5459\\u001b[0;31m         use_legacy_function=use_legacy_function)\\n\\u001b[0m\\u001b[1;32m   5460\\u001b[0m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_metadata\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mdataset_metadata_pb2\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mMetadata\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   5461\\u001b[0m     \\u001b[0;32mif\\u001b[0m \\u001b[0mname\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\\u001b[0m\\n\\u001b[1;32m   4531\\u001b[0m         \\u001b[0mfn_factory\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mtrace_tf_function\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mdefun_kwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   4532\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 4533\\u001b[0;31m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_function\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mfn_factory\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   4534\\u001b[0m     \\u001b[0;31m# There is no graph to add in eager mode.\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   4535\\u001b[0m     \\u001b[0madd_to_graph\\u001b[0m \\u001b[0;34m&=\\u001b[0m \\u001b[0;32mnot\\u001b[0m \\u001b[0mcontext\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mexecuting_eagerly\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\\u001b[0m in \\u001b[0;36mget_concrete_function\\u001b[0;34m(self, *args, **kwargs)\\u001b[0m\\n\\u001b[1;32m   3243\\u001b[0m     \\\"\\\"\\\"\\n\\u001b[1;32m   3244\\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\\n\\u001b[0;32m-> 3245\\u001b[0;31m         *args, **kwargs)\\n\\u001b[0m\\u001b[1;32m   3246\\u001b[0m     \\u001b[0mgraph_function\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_garbage_collector\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mrelease\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m  \\u001b[0;31m# pylint: disable=protected-access\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3247\\u001b[0m     \\u001b[0;32mreturn\\u001b[0m \\u001b[0mgraph_function\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\\u001b[0m in \\u001b[0;36m_get_concrete_function_garbage_collected\\u001b[0;34m(self, *args, **kwargs)\\u001b[0m\\n\\u001b[1;32m   3208\\u001b[0m       \\u001b[0margs\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mkwargs\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3209\\u001b[0m     \\u001b[0;32mwith\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_lock\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 3210\\u001b[0;31m       \\u001b[0mgraph_function\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0m_\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_maybe_define_function\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   3211\\u001b[0m       \\u001b[0mseen_names\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mset\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3212\\u001b[0m       captured = object_identity.ObjectIdentitySet(\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\\u001b[0m in \\u001b[0;36m_maybe_define_function\\u001b[0;34m(self, args, kwargs)\\u001b[0m\\n\\u001b[1;32m   3555\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3556\\u001b[0m           \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_function_cache\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mmissed\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0madd\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mcall_context_key\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 3557\\u001b[0;31m           \\u001b[0mgraph_function\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_create_graph_function\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0margs\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   3558\\u001b[0m           \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_function_cache\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mprimary\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0mcache_key\\u001b[0m\\u001b[0;34m]\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mgraph_function\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3559\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\\u001b[0m in \\u001b[0;36m_create_graph_function\\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\\u001b[0m\\n\\u001b[1;32m   3400\\u001b[0m             \\u001b[0marg_names\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0marg_names\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3401\\u001b[0m             \\u001b[0moverride_flat_arg_shapes\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0moverride_flat_arg_shapes\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 3402\\u001b[0;31m             capture_by_value=self._capture_by_value),\\n\\u001b[0m\\u001b[1;32m   3403\\u001b[0m         \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_function_attributes\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3404\\u001b[0m         \\u001b[0mfunction_spec\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mfunction_spec\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\\u001b[0m in \\u001b[0;36mfunc_graph_from_py_func\\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\\u001b[0m\\n\\u001b[1;32m   1026\\u001b[0m   \\u001b[0;32mif\\u001b[0m \\u001b[0mfunc_graph\\u001b[0m \\u001b[0;32mis\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1027\\u001b[0m     func_graph = FuncGraph(name, collections=collections,\\n\\u001b[0;32m-> 1028\\u001b[0;31m                            capture_by_value=capture_by_value)\\n\\u001b[0m\\u001b[1;32m   1029\\u001b[0m   \\u001b[0;32massert\\u001b[0m \\u001b[0misinstance\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mfunc_graph\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mFuncGraph\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1030\\u001b[0m   \\u001b[0;32mif\\u001b[0m \\u001b[0madd_control_dependencies\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self, name, collections, capture_by_value)\\u001b[0m\\n\\u001b[1;32m    188\\u001b[0m         \\u001b[0;32mfrom\\u001b[0m \\u001b[0mouter\\u001b[0m \\u001b[0mgraphs\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;32mand\\u001b[0m \\u001b[0mfailing\\u001b[0m \\u001b[0mthat\\u001b[0m \\u001b[0mwill\\u001b[0m \\u001b[0mdefault\\u001b[0m \\u001b[0mto\\u001b[0m \\u001b[0;32mFalse\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    189\\u001b[0m     \\\"\\\"\\\"\\n\\u001b[0;32m--> 190\\u001b[0;31m     \\u001b[0msuper\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mFuncGraph\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m__init__\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    191\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    192\\u001b[0m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mname\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mname\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self)\\u001b[0m\\n\\u001b[1;32m   3020\\u001b[0m     \\u001b[0;31m# Similarly, if one or more Session.run calls are going on, all mutate ops\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3021\\u001b[0m     \\u001b[0;31m# have to wait until all Session.run calls have finished.\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 3022\\u001b[0;31m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_group_lock\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mlock_util\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mGroupLock\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mnum_groups\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;36m2\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   3023\\u001b[0m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_nodes_by_id\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m{\\u001b[0m\\u001b[0;34m}\\u001b[0m  \\u001b[0;31m# GUARDED_BY(self._lock)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   3024\\u001b[0m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_next_id_counter\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;36m0\\u001b[0m  \\u001b[0;31m# GUARDED_BY(self._lock)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lock_util.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self, num_groups)\\u001b[0m\\n\\u001b[1;32m     71\\u001b[0m           \\u001b[0;34m\\\"Argument `num_groups` must be a positive integer. \\\"\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     72\\u001b[0m           f\\\"Received: num_groups={num_groups}\\\")\\n\\u001b[0;32m---> 73\\u001b[0;31m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_ready\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mthreading\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mCondition\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mthreading\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mLock\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     74\\u001b[0m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_num_groups\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mnum_groups\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     75\\u001b[0m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_group_member_counts\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;36m0\\u001b[0m\\u001b[0;34m]\\u001b[0m \\u001b[0;34m*\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_num_groups\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;32m/usr/lib/python3.7/threading.py\\u001b[0m in \\u001b[0;36m__init__\\u001b[0;34m(self, lock)\\u001b[0m\\n\\u001b[1;32m    220\\u001b[0m         \\u001b[0;31m# Export the lock's acquire() and release() methods\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    221\\u001b[0m         \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0macquire\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mlock\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0macquire\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 222\\u001b[0;31m         \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mrelease\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mlock\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mrelease\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    223\\u001b[0m         \\u001b[0;31m# If the lock defines _release_save() and/or _acquire_restore(),\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    224\\u001b[0m         \\u001b[0;31m# these override the default implementations (which just call\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "            \"\\u001b[0;31mKeyboardInterrupt\\u001b[0m: \"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"po-jSQoN1Azl\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### **8) Making GIF**\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"XPShgQpg1EMy\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Display a single image using the epoch number\\n\",\n",
    "        \"# def display_image(epoch_no):\\n\",\n",
    "        \"#   return PIL.Image.open('generated_images/%.8f.png'.format(epoch_no))\\n\",\n",
    "        \"\\n\",\n",
    "        \"anim_file = 'dcgan.gif'\\n\",\n",
    "        \"\\n\",\n",
    "        \"with imageio.get_writer(anim_file, mode='I') as writer:\\n\",\n",
    "        \"  filenames = glob.glob('generated_images/*.png')\\n\",\n",
    "        \"  filenames = sorted(filenames)\\n\",\n",
    "        \"  for filename in filenames:\\n\",\n",
    "        \"    image = imageio.imread(filename)\\n\",\n",
    "        \"    writer.append_data(image)\\n\",\n",
    "        \"  image = imageio.imread(filename)\\n\",\n",
    "        \"  writer.append_data(image)\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Wh37uv1torG5\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"\"\n",
    "      ],\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
